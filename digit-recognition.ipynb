{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we are not working with tabular data but with unstructured data because the data is images.\n",
    "Therefore, there is not much of a need to use df.describe for the descriptive statistics.\n",
    "Also no need for df.info as the dataframe is self-explanatory. There is no null values.\n",
    "\n",
    "1. `Origin`: where the data is from, either Chars74K or MNIST datasets.\n",
    "2. `Group`: the segment of the image's quality. It holds values of Hnd (hand written), Fnt (computer font), GoodImg (natural scenes with good quality) and BadImg (natural scenes with bad quality).\n",
    "3. `File`: file path of the images' location.\n",
    "4. `Label`: the images' digit/number.\n",
    "\n",
    "We will make a copy of the original data before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>group</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71589</th>\n",
       "      <td>mnist</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>0</td>\n",
       "      <td>mnist_png/Hnd/Sample0/49278.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66923</th>\n",
       "      <td>mnist</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>0</td>\n",
       "      <td>mnist_png/Hnd/Sample0/7985.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66924</th>\n",
       "      <td>mnist</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>0</td>\n",
       "      <td>mnist_png/Hnd/Sample0/33087.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66925</th>\n",
       "      <td>mnist</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>0</td>\n",
       "      <td>mnist_png/Hnd/Sample0/2996.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66926</th>\n",
       "      <td>mnist</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>0</td>\n",
       "      <td>mnist_png/Hnd/Sample0/19845.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55408</th>\n",
       "      <td>mnist</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>9</td>\n",
       "      <td>mnist_png/Hnd/Sample9/5817.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55407</th>\n",
       "      <td>mnist</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>9</td>\n",
       "      <td>mnist_png/Hnd/Sample9/29536.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55406</th>\n",
       "      <td>mnist</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>9</td>\n",
       "      <td>mnist_png/Hnd/Sample9/37062.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55416</th>\n",
       "      <td>mnist</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>9</td>\n",
       "      <td>mnist_png/Hnd/Sample9/44592.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8257</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Fnt</td>\n",
       "      <td>9</td>\n",
       "      <td>chars74k_png/Fnt/Sample9/img010-00761.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71590 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         origin group  label                                       file\n",
       "71589     mnist   Hnd      0            mnist_png/Hnd/Sample0/49278.png\n",
       "66923     mnist   Hnd      0             mnist_png/Hnd/Sample0/7985.png\n",
       "66924     mnist   Hnd      0            mnist_png/Hnd/Sample0/33087.png\n",
       "66925     mnist   Hnd      0             mnist_png/Hnd/Sample0/2996.png\n",
       "66926     mnist   Hnd      0            mnist_png/Hnd/Sample0/19845.png\n",
       "...         ...   ...    ...                                        ...\n",
       "55408     mnist   Hnd      9             mnist_png/Hnd/Sample9/5817.png\n",
       "55407     mnist   Hnd      9            mnist_png/Hnd/Sample9/29536.png\n",
       "55406     mnist   Hnd      9            mnist_png/Hnd/Sample9/37062.png\n",
       "55416     mnist   Hnd      9            mnist_png/Hnd/Sample9/44592.png\n",
       "8257   chars74k   Fnt      9  chars74k_png/Fnt/Sample9/img010-00761.png\n",
       "\n",
       "[71590 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = pd.read_csv('./data/numbers.csv')\n",
    "df = original_df.copy()\n",
    "df.sort_values('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "origin    0\n",
       "group     0\n",
       "label     0\n",
       "file      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to take into account that there is no need for our digit recognition model to recognize the digit '0' because we are creating a model specialized for Sudoku. As a reminder, Sudoku is a puzzle that involves only the digits from 1-9. That is why we will be removing the 0.\n",
    "\n",
    "Some advantages of doing so:\n",
    "1. by focusing on the digits that are relevant to the task, the model will be more specialized and better suited for the intended application.\n",
    "2. it simplifies the training process and reduces the complexity of the model, leading to a faster training time and potentially better performance on the digits relevant to the task.\n",
    "3. it helps balance the distribution of digits in the dataset preventing the model from being biased towards the majority class (1-9) and improve its ability to generalize.\n",
    "\n",
    "And we can see that the data for the 0 were 7147 and we will be dropping these values from the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of the digit 0 in the dataset: 7147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    7938\n",
       "2    7147\n",
       "3    7274\n",
       "4    6986\n",
       "5    6573\n",
       "6    7073\n",
       "7    7397\n",
       "8    6964\n",
       "9    7091\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_0 = df['origin'].loc[df['label'] == 0].count()\n",
    "print(f'Count of the digit 0 in the dataset: {freq_0}')\n",
    "\n",
    "df = df.loc[df['label'] != 0]\n",
    "df['label'].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that after removing 0's in our dataset we have 54,077 images from the MNIST and 10,366 images from Chars74K.\n",
    "So approximately 84% belongs to MNIST and 16% to Chars74k.\n",
    "This ratio will be used for stratified sampling of train and test sets along with the proportion of the 'group' and 'label' features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>count</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mnist</td>\n",
       "      <td>54077</td>\n",
       "      <td>0.839145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>10366</td>\n",
       "      <td>0.160855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     origin  count     ratio\n",
       "0     mnist  54077  0.839145\n",
       "1  chars74k  10366  0.160855"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_datasets = df['origin'].value_counts().reset_index()\n",
    "df_datasets['ratio'] = df_datasets['count'] / df_datasets['count'].sum()\n",
    "df_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will further see the count of each label within it's group.\n",
    "The MNIST dataset only contains handwritten digits while the Chars74k contains bad images, good images, and computer fonts as well.\n",
    "Now we are ready to separate the origin of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>group</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>BadImag</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.000745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>BadImag</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>0.000745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>BadImag</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>BadImag</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>BadImag</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>BadImag</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>BadImag</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>BadImag</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>BadImag</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Fnt</td>\n",
       "      <td>1</td>\n",
       "      <td>1016</td>\n",
       "      <td>0.015766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Fnt</td>\n",
       "      <td>2</td>\n",
       "      <td>1016</td>\n",
       "      <td>0.015766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Fnt</td>\n",
       "      <td>3</td>\n",
       "      <td>1016</td>\n",
       "      <td>0.015766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Fnt</td>\n",
       "      <td>4</td>\n",
       "      <td>1016</td>\n",
       "      <td>0.015766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Fnt</td>\n",
       "      <td>5</td>\n",
       "      <td>1016</td>\n",
       "      <td>0.015766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Fnt</td>\n",
       "      <td>6</td>\n",
       "      <td>1016</td>\n",
       "      <td>0.015766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Fnt</td>\n",
       "      <td>7</td>\n",
       "      <td>1016</td>\n",
       "      <td>0.015766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Fnt</td>\n",
       "      <td>8</td>\n",
       "      <td>1016</td>\n",
       "      <td>0.015766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Fnt</td>\n",
       "      <td>9</td>\n",
       "      <td>1016</td>\n",
       "      <td>0.015766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>GoodImg</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>0.001195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>GoodImg</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>0.001086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>GoodImg</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>GoodImg</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>0.000729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>GoodImg</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>GoodImg</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>GoodImg</td>\n",
       "      <td>7</td>\n",
       "      <td>48</td>\n",
       "      <td>0.000745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>GoodImg</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.000497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>GoodImg</td>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "      <td>0.000528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0.000853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>0.000853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>0.000853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>4</td>\n",
       "      <td>55</td>\n",
       "      <td>0.000853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>0.000853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>6</td>\n",
       "      <td>55</td>\n",
       "      <td>0.000853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>7</td>\n",
       "      <td>55</td>\n",
       "      <td>0.000853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>8</td>\n",
       "      <td>55</td>\n",
       "      <td>0.000853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>9</td>\n",
       "      <td>55</td>\n",
       "      <td>0.000853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>mnist</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>1</td>\n",
       "      <td>6742</td>\n",
       "      <td>0.104620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>mnist</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>2</td>\n",
       "      <td>5958</td>\n",
       "      <td>0.092454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>mnist</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>3</td>\n",
       "      <td>6131</td>\n",
       "      <td>0.095138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>mnist</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>4</td>\n",
       "      <td>5842</td>\n",
       "      <td>0.090654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>mnist</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>5</td>\n",
       "      <td>5421</td>\n",
       "      <td>0.084121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>mnist</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>6</td>\n",
       "      <td>5918</td>\n",
       "      <td>0.091833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>mnist</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>7</td>\n",
       "      <td>6265</td>\n",
       "      <td>0.097218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>mnist</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>8</td>\n",
       "      <td>5851</td>\n",
       "      <td>0.090793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>mnist</td>\n",
       "      <td>Hnd</td>\n",
       "      <td>9</td>\n",
       "      <td>5949</td>\n",
       "      <td>0.092314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      origin    group  label  file     ratio\n",
       "0   chars74k  BadImag      1    48  0.000745\n",
       "1   chars74k  BadImag      2    48  0.000745\n",
       "2   chars74k  BadImag      3    22  0.000341\n",
       "3   chars74k  BadImag      4    26  0.000403\n",
       "4   chars74k  BadImag      5    17  0.000264\n",
       "5   chars74k  BadImag      6    20  0.000310\n",
       "6   chars74k  BadImag      7    13  0.000202\n",
       "7   chars74k  BadImag      8    10  0.000155\n",
       "8   chars74k  BadImag      9    37  0.000574\n",
       "9   chars74k      Fnt      1  1016  0.015766\n",
       "10  chars74k      Fnt      2  1016  0.015766\n",
       "11  chars74k      Fnt      3  1016  0.015766\n",
       "12  chars74k      Fnt      4  1016  0.015766\n",
       "13  chars74k      Fnt      5  1016  0.015766\n",
       "14  chars74k      Fnt      6  1016  0.015766\n",
       "15  chars74k      Fnt      7  1016  0.015766\n",
       "16  chars74k      Fnt      8  1016  0.015766\n",
       "17  chars74k      Fnt      9  1016  0.015766\n",
       "18  chars74k  GoodImg      1    77  0.001195\n",
       "19  chars74k  GoodImg      2    70  0.001086\n",
       "20  chars74k  GoodImg      3    50  0.000776\n",
       "21  chars74k  GoodImg      4    47  0.000729\n",
       "22  chars74k  GoodImg      5    64  0.000993\n",
       "23  chars74k  GoodImg      6    64  0.000993\n",
       "24  chars74k  GoodImg      7    48  0.000745\n",
       "25  chars74k  GoodImg      8    32  0.000497\n",
       "26  chars74k  GoodImg      9    34  0.000528\n",
       "27  chars74k      Hnd      1    55  0.000853\n",
       "28  chars74k      Hnd      2    55  0.000853\n",
       "29  chars74k      Hnd      3    55  0.000853\n",
       "30  chars74k      Hnd      4    55  0.000853\n",
       "31  chars74k      Hnd      5    55  0.000853\n",
       "32  chars74k      Hnd      6    55  0.000853\n",
       "33  chars74k      Hnd      7    55  0.000853\n",
       "34  chars74k      Hnd      8    55  0.000853\n",
       "35  chars74k      Hnd      9    55  0.000853\n",
       "36     mnist      Hnd      1  6742  0.104620\n",
       "37     mnist      Hnd      2  5958  0.092454\n",
       "38     mnist      Hnd      3  6131  0.095138\n",
       "39     mnist      Hnd      4  5842  0.090654\n",
       "40     mnist      Hnd      5  5421  0.084121\n",
       "41     mnist      Hnd      6  5918  0.091833\n",
       "42     mnist      Hnd      7  6265  0.097218\n",
       "43     mnist      Hnd      8  5851  0.090793\n",
       "44     mnist      Hnd      9  5949  0.092314"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = df.groupby(['origin','group','label'])['file'].count().reset_index()\n",
    "df_labels['ratio'] = df_labels['file'] / df_labels['file'].sum()\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will decide to remove the bad quality images (BadImag) because we are not going to deploy the model to recognize bad quality digits and also the amount of pictures are way too few to have a positive effect on the model. In doing so we will reduce some bias and noise to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mnist = df.loc[df['origin']=='mnist']\n",
    "df_chars74k = df.loc[(df['origin']=='chars74k') & (df['group']!='BadImag')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that for the MNIST dataset, the group feature's information is quite insignificant to keep because it has only one category, which is handwritten digits so it is okay to drop the whole column.  \n",
    "\n",
    "The group for the Chars74k set will be kept to use for the parameter 'stratify' later when we split the train and test sets.  \n",
    "\n",
    "Finally, the 'origin' column for both datasets will be dropped afterwards because we only need the location of the files (which will be read and the images be converted into an array of pixels for 'X') and the label (which will be the 'y').  \n",
    "\n",
    "`explanatory variables`: X (array of dimensions: m,n where m is individual data and n is amount of pixels)  \n",
    "`target variable`: y (array of single dimension (m,) where m is label for each individual data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qz/5wqlq53516nf38l3j5wtkvmh0000gn/T/ipykernel_93322/2903635121.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_mnist.drop(columns='group', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38628</th>\n",
       "      <td>mnist</td>\n",
       "      <td>1</td>\n",
       "      <td>mnist_png/Hnd/Sample1/3963.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37325</th>\n",
       "      <td>mnist</td>\n",
       "      <td>1</td>\n",
       "      <td>mnist_png/Hnd/Sample1/18266.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37326</th>\n",
       "      <td>mnist</td>\n",
       "      <td>1</td>\n",
       "      <td>mnist_png/Hnd/Sample1/19346.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37327</th>\n",
       "      <td>mnist</td>\n",
       "      <td>1</td>\n",
       "      <td>mnist_png/Hnd/Sample1/21972.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37328</th>\n",
       "      <td>mnist</td>\n",
       "      <td>1</td>\n",
       "      <td>mnist_png/Hnd/Sample1/53823.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      origin  label                             file\n",
       "38628  mnist      1   mnist_png/Hnd/Sample1/3963.png\n",
       "37325  mnist      1  mnist_png/Hnd/Sample1/18266.png\n",
       "37326  mnist      1  mnist_png/Hnd/Sample1/19346.png\n",
       "37327  mnist      1  mnist_png/Hnd/Sample1/21972.png\n",
       "37328  mnist      1  mnist_png/Hnd/Sample1/53823.png"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    df_mnist.drop(columns='group', inplace=True)\n",
    "except KeyError:\n",
    "    print('The column \"group\" has already been dropped.')\n",
    "df_mnist.sort_values('label').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>group</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Fnt</td>\n",
       "      <td>1</td>\n",
       "      <td>chars74k_png/Fnt/Sample1/img002-00203.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5046</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Fnt</td>\n",
       "      <td>1</td>\n",
       "      <td>chars74k_png/Fnt/Sample1/img002-00186.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5045</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Fnt</td>\n",
       "      <td>1</td>\n",
       "      <td>chars74k_png/Fnt/Sample1/img002-00564.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5044</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Fnt</td>\n",
       "      <td>1</td>\n",
       "      <td>chars74k_png/Fnt/Sample1/img002-00153.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5043</th>\n",
       "      <td>chars74k</td>\n",
       "      <td>Fnt</td>\n",
       "      <td>1</td>\n",
       "      <td>chars74k_png/Fnt/Sample1/img002-00036.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        origin group  label                                       file\n",
       "5167  chars74k   Fnt      1  chars74k_png/Fnt/Sample1/img002-00203.png\n",
       "5046  chars74k   Fnt      1  chars74k_png/Fnt/Sample1/img002-00186.png\n",
       "5045  chars74k   Fnt      1  chars74k_png/Fnt/Sample1/img002-00564.png\n",
       "5044  chars74k   Fnt      1  chars74k_png/Fnt/Sample1/img002-00153.png\n",
       "5043  chars74k   Fnt      1  chars74k_png/Fnt/Sample1/img002-00036.png"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chars74k.sort_values('label').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data into Train, Validation, Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data will be separated into X and y then we split the train, validation, and test sets with stratified sampling on the labels.\n",
    "\n",
    "Let's start with the MNIST dataset because it is easier to do without the groups.\n",
    "\n",
    "The steps will be:\n",
    "1. work without the origin column as the variable name will hold the dataset's name.\n",
    "2. separate the X and y.\n",
    "3. check the shape to make sure the dimensions are right.\n",
    "4. separate into train and test sets with the stratify parameter being the label feature.\n",
    "5. then drop the label column from X because it was only used for stratification.\n",
    "6. check the shape to make sure the dimensions are right again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mnist = df_mnist[['file','label']]\n",
    "y_mnist = df_mnist['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_mnist.shape = (54077, 2)\n",
      "y_mnist.shape = (54077,)\n"
     ]
    }
   ],
   "source": [
    "print(f'{X_mnist.shape = }')\n",
    "print(f'{y_mnist.shape = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_mnist.shape = (46235, 2)\n",
      "y_train_mnist.shape = (46235,)\n",
      "X_val_mnist.shape = (5138, 2)\n",
      "y_val_mnist.shape = (5138,)\n",
      "X_test_mnist.shape = (2704, 2)\n",
      "y_test_mnist.shape = (2704,)\n"
     ]
    }
   ],
   "source": [
    "X_train_mnist, X_test_mnist, y_train_mnist, y_test_mnist = train_test_split(X_mnist, y_mnist, test_size=0.05, stratify=X_mnist['label'])\n",
    "X_train_mnist, X_val_mnist, y_train_mnist, y_val_mnist = train_test_split(X_train_mnist, y_train_mnist, test_size=0.1, stratify=X_train_mnist['label'])\n",
    "\n",
    "print(f'{X_train_mnist.shape = }')\n",
    "print(f'{y_train_mnist.shape = }')\n",
    "print(f'{X_val_mnist.shape = }')\n",
    "print(f'{y_val_mnist.shape = }')\n",
    "print(f'{X_test_mnist.shape = }')\n",
    "print(f'{y_test_mnist.shape = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets do the same procedure for the Chars74k dataset.\n",
    "\n",
    "For this dataset first we have to loop into every group and then perform the train test split.\n",
    "\n",
    "The steps will be:\n",
    "1. get hold of the unique group feature values.\n",
    "2. initialize an empty list to get hold of the X_train, X_test, y_train, y_test of each group.\n",
    "3. perform the train test split with the stratify parameter being the label.\n",
    "4. append each of the values to the empty list.\n",
    "5. concatenate all the train test splits of every group.\n",
    "6. then split the data again to make the validation sets.\n",
    "7. check for the shapes to make sure the dimensions are right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_chars74k.shape = (8655, 2)\n",
      "y_train_chars74k.shape = (8655,)\n",
      "X_val_chars74k.shape = (962, 2)\n",
      "y_val_chars74k.shape = (962,)\n",
      "X_test_chars74k.shape = (508, 2)\n",
      "y_test_chars74k.shape = (508,)\n"
     ]
    }
   ],
   "source": [
    "df_chars74k_groups = df_chars74k['group'].unique().tolist()\n",
    "X_train_list, X_test_list, y_train_list, y_test_list = [], [], [], []\n",
    "for group in df_chars74k_groups:\n",
    "    df_group = df_chars74k.loc[df['group'] == group]\n",
    "    \n",
    "    X_train_chars74k, X_test_chars74k, y_train_chars74k, y_test_chars74k = train_test_split(\n",
    "        df_group[['file','label']], df_group['label'], test_size=0.05, stratify=df_group['label']\n",
    "    )\n",
    "    X_train_list.append(X_train_chars74k)\n",
    "    X_test_list.append(X_test_chars74k)\n",
    "    y_train_list.append(y_train_chars74k)\n",
    "    y_test_list.append(y_test_chars74k)\n",
    "\n",
    "X_train_chars74k = pd.concat(X_train_list)\n",
    "X_test_chars74k = pd.concat(X_test_list)\n",
    "y_train_chars74k = pd.concat(y_train_list)\n",
    "y_test_chars74k = pd.concat(y_test_list)\n",
    "\n",
    "X_train_chars74k, X_val_chars74k, y_train_chars74k, y_val_chars74k = train_test_split(\n",
    "    X_train_chars74k, y_train_chars74k, test_size=0.1, stratify=X_train_chars74k['label']\n",
    ")\n",
    "\n",
    "\n",
    "print(f'{X_train_chars74k.shape = }')\n",
    "print(f'{y_train_chars74k.shape = }')\n",
    "print(f'{X_val_chars74k.shape = }')\n",
    "print(f'{y_val_chars74k.shape = }')\n",
    "print(f'{X_test_chars74k.shape = }')\n",
    "print(f'{y_test_chars74k.shape = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets check that the proportion of the groups were done correctly.  \n",
    "\n",
    "Let's see the proportion of groups before and after the train test split. We will do so with only the X test just to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   label  file     ratio\n",
       " 0      1  6742  0.124674\n",
       " 1      2  5958  0.110176\n",
       " 2      3  6131  0.113375\n",
       " 3      4  5842  0.108031\n",
       " 4      5  5421  0.100246\n",
       " 5      6  5918  0.109437\n",
       " 6      7  6265  0.115853\n",
       " 7      8  5851  0.108198\n",
       " 8      9  5949  0.110010,\n",
       "    label  file     ratio\n",
       " 0      1   337  0.124630\n",
       " 1      2   298  0.110207\n",
       " 2      3   307  0.113536\n",
       " 3      4   292  0.107988\n",
       " 4      5   271  0.100222\n",
       " 5      6   296  0.109467\n",
       " 6      7   313  0.115754\n",
       " 7      8   293  0.108358\n",
       " 8      9   297  0.109837)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mnist_labels = df_mnist.groupby('label')['file'].count().reset_index()\n",
    "df_mnist_labels['ratio'] = df_mnist_labels['file'] / df_mnist_labels['file'].sum()\n",
    "df_mnist_labels\n",
    "\n",
    "X_test_mnist_labels = X_test_mnist.groupby('label')['file'].count().reset_index()\n",
    "X_test_mnist_labels['ratio'] = X_test_mnist_labels['file'] / X_test_mnist_labels['file'].sum()\n",
    "X_test_mnist_labels\n",
    "\n",
    "df_mnist_labels, X_test_mnist_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   label  file     ratio\n",
       " 0      1  1148  0.113383\n",
       " 1      2  1141  0.112691\n",
       " 2      3  1121  0.110716\n",
       " 3      4  1118  0.110420\n",
       " 4      5  1135  0.112099\n",
       " 5      6  1135  0.112099\n",
       " 6      7  1119  0.110519\n",
       " 7      8  1103  0.108938\n",
       " 8      9  1105  0.109136,\n",
       "    label  file     ratio\n",
       " 0      1    57  0.112205\n",
       " 1      2    58  0.114173\n",
       " 2      3    57  0.112205\n",
       " 3      4    56  0.110236\n",
       " 4      5    56  0.110236\n",
       " 5      6    57  0.112205\n",
       " 6      7    56  0.110236\n",
       " 7      8    55  0.108268\n",
       " 8      9    56  0.110236)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chars74k_labels = df_chars74k.groupby('label')['file'].count().reset_index()\n",
    "df_chars74k_labels['ratio'] = df_chars74k_labels['file'] / df_chars74k_labels['file'].sum()\n",
    "df_chars74k_labels\n",
    "\n",
    "X_test_chars74k_labels = X_test_chars74k.groupby('label')['file'].count().reset_index()\n",
    "X_test_chars74k_labels['ratio'] = X_test_chars74k_labels['file'] / X_test_chars74k_labels['file'].sum()\n",
    "X_test_chars74k_labels\n",
    "\n",
    "df_chars74k_labels, X_test_chars74k_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can drop the label columns for the X in both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mnist.drop(columns='label', inplace=True)\n",
    "X_val_mnist.drop(columns='label', inplace=True)\n",
    "X_test_mnist.drop(columns='label', inplace=True)\n",
    "X_train_chars74k.drop(columns='label', inplace=True)\n",
    "X_val_chars74k.drop(columns='label', inplace=True)\n",
    "X_test_chars74k.drop(columns='label', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_chars74k.shape = (8655, 1)\n",
      "y_train_chars74k.shape = (8655,)\n",
      "X_val_chars74k.shape = (962, 1)\n",
      "y_val_chars74k.shape = (962,)\n",
      "X_test_chars74k.shape = (508, 1)\n",
      "y_test_chars74k.shape = (508,)\n",
      "X_train_mnist.shape = (46235, 1)\n",
      "y_train_mnist.shape = (46235,)\n",
      "X_val_mnist.shape = (5138, 1)\n",
      "y_val_mnist.shape = (5138,)\n",
      "X_test_mnist.shape = (2704, 1)\n",
      "y_test_mnist.shape = (2704,)\n"
     ]
    }
   ],
   "source": [
    "print(f'{X_train_chars74k.shape = }')\n",
    "print(f'{y_train_chars74k.shape = }')\n",
    "print(f'{X_val_chars74k.shape = }')\n",
    "print(f'{y_val_chars74k.shape = }')\n",
    "print(f'{X_test_chars74k.shape = }')\n",
    "print(f'{y_test_chars74k.shape = }')\n",
    "print(f'{X_train_mnist.shape = }')\n",
    "print(f'{y_train_mnist.shape = }')\n",
    "print(f'{X_val_mnist.shape = }')\n",
    "print(f'{y_val_mnist.shape = }')\n",
    "print(f'{X_test_mnist.shape = }')\n",
    "print(f'{y_test_mnist.shape = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to concatenate both datasets into one X_train, X_test, X_val, y_train, y_val, y_test and subtract 1 from all y's because we are only using from 0~9 and so we will need an output layer of size 9 later on when we build the model. The intuition in this process is that computers start counting from 0 and because the output layer is size 9 it will go from 0~8 whereas our labels are from 1~9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train_chars74k, X_train_mnist])\n",
    "y_train = pd.concat([y_train_chars74k, y_train_mnist]) - 1\n",
    "X_val = pd.concat([X_val_chars74k, X_val_mnist])\n",
    "y_val = pd.concat([y_val_chars74k, y_val_mnist]) - 1\n",
    "X_test = pd.concat([X_test_chars74k, X_test_mnist])\n",
    "y_test = pd.concat([y_test_chars74k, y_test_mnist]) - 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess images for Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the X holds the value of file path to the image and so we need to be able to get the images in those file paths, convert those images into pixel values and then make each pixel value be one feature or column in the new X.\n",
    "\n",
    "Until now we were exploring and cleaning data from different datasets with different structures but now that we have combined and we are ready for preprocessing the data for machine learning, we will be using functions later to be saved in the utils.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "def df_to_pixels_array(df:pd.DataFrame, label:str, resize_dim:tuple, rel_path) -> np.array:\n",
    "    \"\"\"\n",
    "    Takes a column from a pandas dataframe that has the values for the file path of images.\n",
    "    Then it reads the files, converts them to grayscale and flattens the pixel values\n",
    "    to finally return a numpy array of those values.\n",
    "\n",
    "    Parameters:\n",
    "    df_filepath (dataframe): The dataframe to process.\n",
    "    label (string): The name of the column containing the file paths\n",
    "    resize (tuple): The dimensions to resize the image before flattening.\n",
    "    rel_path (string): The relative file path before the value in the dataframe column.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    array: (m, n) numpy array of grayscale pixel values.\n",
    "            m -> # of images\n",
    "            n -> product of resize tuple provided\n",
    "    \"\"\"\n",
    "    i = len(df[label])\n",
    "    m = resize_dim[0]\n",
    "    n = resize_dim[1]\n",
    "    df_array = np.zeros((i, m, n), dtype=np.uint8)\n",
    "    for index, file_path in enumerate(df[label]):\n",
    "        file_path = rel_path + file_path\n",
    "        image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.equalizeHist(image)\n",
    "        image = cv2.resize(image, resize_dim)\n",
    "        if image is None:\n",
    "            print(\"Error: Unable to read the image.\")\n",
    "            print(file_path)\n",
    "        else:\n",
    "            df_array[index] = image\n",
    "    return df_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_path = './images/numbers/'\n",
    "label = 'file'\n",
    "resize_dim = (32,32)\n",
    "X_train = df_to_pixels_array(X_train, label, resize_dim, rel_path)\n",
    "X_val = df_to_pixels_array(X_val, label, resize_dim, rel_path)\n",
    "X_test = df_to_pixels_array(X_test, label, resize_dim, rel_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the dimensions and datatypes are correct for X_train, X_val, and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (54890, 32, 32)\n",
      "X_val.shape = (6100, 32, 32)\n",
      "X_test.shape = (3212, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(f'{X_train.shape = }')\n",
    "print(f'{X_val.shape = }')\n",
    "print(f'{X_test.shape = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time for further preprocessing before we train the Convolutional Neural Network for it to be able to predict numbers.  \n",
    "Specifically, we are going to normalize the data. Right now, the range of each pixel is from 0, 255 with 0 being black and 255 white. By normalizing the data the range will be from 0~1 conserving the ratio, and this will help the model to converge more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.keras.utils.normalize(X_train, axis=1)\n",
    "X_train = np.array(X_train).reshape(-1, resize_dim[0], resize_dim[1], 1)\n",
    "X_val = tf.keras.utils.normalize(X_val, axis=1)\n",
    "X_val = np.array(X_val).reshape(-1, resize_dim[0], resize_dim[1], 1)\n",
    "X_test = tf.keras.utils.normalize(X_test, axis=1)\n",
    "X_test = np.array(X_test).reshape(-1, resize_dim[0], resize_dim[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Convolutional Neural Network Model to train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we build the arquitecture for the CNN and compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertopark/Documents/code-projects/datascience-projects/sudoku-solver-app/.venv/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_6           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_7           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_8           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_9           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_10          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_11          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,225</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚           \u001b[38;5;34m320\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_6           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚         \u001b[38;5;34m9,248\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_7           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚        \u001b[38;5;34m18,496\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_8           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       â”‚        \u001b[38;5;34m36,928\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_9           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚       \u001b[38;5;34m131,584\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_10          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚         \u001b[38;5;34m2,048\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           â”‚       \u001b[38;5;34m525,312\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_11          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           â”‚         \u001b[38;5;34m4,096\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              â”‚         \u001b[38;5;34m9,225\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">738,025</span> (2.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m738,025\u001b[0m (2.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">734,569</span> (2.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m734,569\u001b[0m (2.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,456</span> (13.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,456\u001b[0m (13.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Conv2D(32, (3,3), padding='valid', activation='relu', input_shape=(X_train.shape[1:])),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32, (3,3), padding='valid', activation='relu', input_shape=(X_train.shape[1:])),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Conv2D(64, (3,3), padding='valid', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2)),\n",
    "        Conv2D(64, (3,3), padding='valid', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(512,activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.25),\n",
    "        Dense(1024,activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.25),\n",
    "        Dense(9, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(\n",
    "    optimizer=optimizer, \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we fit the model we are going to generate batches of augmented data for the X_train and y_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 33ms/step - accuracy: 0.6793 - loss: 0.9976 - val_accuracy: 0.9549 - val_loss: 0.1443\n",
      "Epoch 2/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 33ms/step - accuracy: 0.9210 - loss: 0.2543 - val_accuracy: 0.9710 - val_loss: 0.0907\n",
      "Epoch 3/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 34ms/step - accuracy: 0.9439 - loss: 0.1739 - val_accuracy: 0.9802 - val_loss: 0.0695\n",
      "Epoch 4/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 34ms/step - accuracy: 0.9586 - loss: 0.1318 - val_accuracy: 0.9828 - val_loss: 0.0582\n",
      "Epoch 5/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 33ms/step - accuracy: 0.9650 - loss: 0.1078 - val_accuracy: 0.9825 - val_loss: 0.0557\n",
      "Epoch 6/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 33ms/step - accuracy: 0.9700 - loss: 0.0916 - val_accuracy: 0.9844 - val_loss: 0.0492\n",
      "Epoch 7/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 33ms/step - accuracy: 0.9739 - loss: 0.0808 - val_accuracy: 0.9859 - val_loss: 0.0469\n",
      "Epoch 8/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 32ms/step - accuracy: 0.9757 - loss: 0.0738 - val_accuracy: 0.9867 - val_loss: 0.0423\n",
      "Epoch 9/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 33ms/step - accuracy: 0.9799 - loss: 0.0602 - val_accuracy: 0.9880 - val_loss: 0.0363\n",
      "Epoch 10/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 33ms/step - accuracy: 0.9801 - loss: 0.0598 - val_accuracy: 0.9872 - val_loss: 0.0401\n",
      "Epoch 11/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 32ms/step - accuracy: 0.9825 - loss: 0.0527 - val_accuracy: 0.9897 - val_loss: 0.0365\n",
      "Epoch 12/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 32ms/step - accuracy: 0.9847 - loss: 0.0486 - val_accuracy: 0.9889 - val_loss: 0.0365\n",
      "Epoch 13/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 33ms/step - accuracy: 0.9849 - loss: 0.0469 - val_accuracy: 0.9889 - val_loss: 0.0340\n",
      "Epoch 14/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 33ms/step - accuracy: 0.9872 - loss: 0.0394 - val_accuracy: 0.9897 - val_loss: 0.0345\n",
      "Epoch 15/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 33ms/step - accuracy: 0.9870 - loss: 0.0383 - val_accuracy: 0.9903 - val_loss: 0.0315\n",
      "Epoch 16/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 33ms/step - accuracy: 0.9872 - loss: 0.0370 - val_accuracy: 0.9903 - val_loss: 0.0341\n",
      "Epoch 17/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 33ms/step - accuracy: 0.9883 - loss: 0.0347 - val_accuracy: 0.9903 - val_loss: 0.0312\n",
      "Epoch 18/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 33ms/step - accuracy: 0.9890 - loss: 0.0331 - val_accuracy: 0.9915 - val_loss: 0.0307\n",
      "Epoch 19/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 33ms/step - accuracy: 0.9883 - loss: 0.0342 - val_accuracy: 0.9913 - val_loss: 0.0292\n",
      "Epoch 20/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 33ms/step - accuracy: 0.9909 - loss: 0.0265 - val_accuracy: 0.9913 - val_loss: 0.0286\n",
      "Epoch 21/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 33ms/step - accuracy: 0.9915 - loss: 0.0274 - val_accuracy: 0.9911 - val_loss: 0.0289\n",
      "Epoch 22/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 33ms/step - accuracy: 0.9902 - loss: 0.0292 - val_accuracy: 0.9910 - val_loss: 0.0279\n",
      "Epoch 23/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 33ms/step - accuracy: 0.9917 - loss: 0.0249 - val_accuracy: 0.9913 - val_loss: 0.0274\n",
      "Epoch 24/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 32ms/step - accuracy: 0.9916 - loss: 0.0246 - val_accuracy: 0.9916 - val_loss: 0.0280\n",
      "Epoch 25/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 33ms/step - accuracy: 0.9912 - loss: 0.0245 - val_accuracy: 0.9905 - val_loss: 0.0278\n",
      "Epoch 26/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 33ms/step - accuracy: 0.9927 - loss: 0.0218 - val_accuracy: 0.9934 - val_loss: 0.0242\n",
      "Epoch 27/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 32ms/step - accuracy: 0.9917 - loss: 0.0232 - val_accuracy: 0.9936 - val_loss: 0.0239\n",
      "Epoch 28/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 33ms/step - accuracy: 0.9921 - loss: 0.0224 - val_accuracy: 0.9925 - val_loss: 0.0266\n",
      "Epoch 29/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 33ms/step - accuracy: 0.9938 - loss: 0.0195 - val_accuracy: 0.9902 - val_loss: 0.0312\n",
      "Epoch 30/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 33ms/step - accuracy: 0.9933 - loss: 0.0204 - val_accuracy: 0.9920 - val_loss: 0.0260\n",
      "Epoch 31/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 32ms/step - accuracy: 0.9946 - loss: 0.0173 - val_accuracy: 0.9911 - val_loss: 0.0271\n",
      "Epoch 32/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 33ms/step - accuracy: 0.9942 - loss: 0.0176 - val_accuracy: 0.9911 - val_loss: 0.0311\n",
      "Epoch 33/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 31ms/step - accuracy: 0.9940 - loss: 0.0173 - val_accuracy: 0.9930 - val_loss: 0.0268\n",
      "Epoch 34/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 33ms/step - accuracy: 0.9943 - loss: 0.0166 - val_accuracy: 0.9938 - val_loss: 0.0254\n",
      "Epoch 35/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 31ms/step - accuracy: 0.9942 - loss: 0.0165 - val_accuracy: 0.9923 - val_loss: 0.0266\n",
      "Epoch 36/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 33ms/step - accuracy: 0.9944 - loss: 0.0168 - val_accuracy: 0.9926 - val_loss: 0.0270\n",
      "Epoch 37/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 32ms/step - accuracy: 0.9947 - loss: 0.0152 - val_accuracy: 0.9916 - val_loss: 0.0300\n",
      "Epoch 38/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 32ms/step - accuracy: 0.9949 - loss: 0.0145 - val_accuracy: 0.9930 - val_loss: 0.0256\n",
      "Epoch 39/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 33ms/step - accuracy: 0.9949 - loss: 0.0135 - val_accuracy: 0.9936 - val_loss: 0.0250\n",
      "Epoch 40/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 31ms/step - accuracy: 0.9949 - loss: 0.0142 - val_accuracy: 0.9930 - val_loss: 0.0283\n",
      "Epoch 41/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 32ms/step - accuracy: 0.9950 - loss: 0.0139 - val_accuracy: 0.9939 - val_loss: 0.0269\n",
      "Epoch 42/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 33ms/step - accuracy: 0.9950 - loss: 0.0142 - val_accuracy: 0.9930 - val_loss: 0.0265\n",
      "Epoch 43/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 33ms/step - accuracy: 0.9956 - loss: 0.0130 - val_accuracy: 0.9933 - val_loss: 0.0282\n",
      "Epoch 44/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 34ms/step - accuracy: 0.9957 - loss: 0.0124 - val_accuracy: 0.9925 - val_loss: 0.0298\n",
      "Epoch 45/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 33ms/step - accuracy: 0.9957 - loss: 0.0117 - val_accuracy: 0.9925 - val_loss: 0.0282\n",
      "Epoch 46/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 32ms/step - accuracy: 0.9949 - loss: 0.0139 - val_accuracy: 0.9918 - val_loss: 0.0277\n",
      "Epoch 47/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 33ms/step - accuracy: 0.9952 - loss: 0.0134 - val_accuracy: 0.9926 - val_loss: 0.0277\n",
      "Epoch 48/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 33ms/step - accuracy: 0.9959 - loss: 0.0118 - val_accuracy: 0.9925 - val_loss: 0.0250\n",
      "Epoch 49/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 33ms/step - accuracy: 0.9956 - loss: 0.0121 - val_accuracy: 0.9933 - val_loss: 0.0233\n",
      "Epoch 50/50\n",
      "\u001b[1m1716/1716\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 33ms/step - accuracy: 0.9964 - loss: 0.0122 - val_accuracy: 0.9943 - val_loss: 0.0254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x35e307290>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=10,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     # horizontal_flip=True,\n",
    "#     fill_mode='nearest'\n",
    "# )\n",
    "# datagen.fit(X_train)\n",
    "# train_generator = datagen.flow(X_train, y_train-1, batch_size=32)\n",
    "# model.fit(train_generator, validation_data= (X_val, y_val-1), epochs=5)\n",
    "model.fit(X_train, y_train, validation_data= (X_val, y_val), epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model to the train data, and subtract 1 from y_train as the outputlayer contains 1~9 but counting starts from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train, y_train - 1, epochs=3, validation_split=0.2, batch_size=32, verbose='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model to see how it did on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m101/101\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9904 - loss: 0.0354\n",
      "loss = 0.029760543256998062\n",
      "accuracy = 0.9915940165519714\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'{loss = }')\n",
    "print(f'{accuracy = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make some functions to preprocess the images for the models to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_pixels(image:np.array) -> np.array:\n",
    "    resize_dim = (32, 32)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    equalized_image = cv2.equalizeHist(gray_image)\n",
    "    image = cv2.resize(equalized_image, resize_dim)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pixels(image:np.array) -> np.array:\n",
    "    resize_dim = (32,32)\n",
    "    normalized_image = tf.keras.utils.normalize(image, axis=1)\n",
    "    preprocessed_image = np.array(normalized_image).reshape(-1, resize_dim[0], resize_dim[1], 1)\n",
    "    return preprocessed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to see how well the model predicts with toy data from self made handwritten digits, which is not that very important compared to the actual digits that real Sudoku would hold (mostly computer font digits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "file = 'sudoku-1.png'\n",
      "prediction.round(3) = array([[1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)\n",
      "prediction_label = 1\n",
      "predicted_probability = 0.9999461\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "file = 'sudoku-2.png'\n",
      "prediction.round(3) = array([[0., 1., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)\n",
      "prediction_label = 2\n",
      "predicted_probability = 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "file = 'sudoku-3.png'\n",
      "prediction.round(3) = array([[0., 0., 1., 0., 0., 0., 0., 0., 0.]], dtype=float32)\n",
      "prediction_label = 3\n",
      "predicted_probability = 0.9999969\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "file = 'sudoku-7.png'\n",
      "prediction.round(3) = array([[0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32)\n",
      "prediction_label = 7\n",
      "predicted_probability = 0.99999976\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "file = 'sudoku-6.png'\n",
      "prediction.round(3) = array([[0., 0., 0., 0., 0., 1., 0., 0., 0.]], dtype=float32)\n",
      "prediction_label = 6\n",
      "predicted_probability = 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "file = 'my-8.png'\n",
      "prediction.round(3) = array([[0.   , 0.002, 0.003, 0.   , 0.   , 0.   , 0.   , 0.988, 0.007]],\n",
      "      dtype=float32)\n",
      "prediction_label = 8\n",
      "predicted_probability = 0.98789924\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "file = 'sudoku-4.png'\n",
      "prediction.round(3) = array([[0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)\n",
      "prediction_label = 4\n",
      "predicted_probability = 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "file = 'sudoku-5.png'\n",
      "prediction.round(3) = array([[0., 0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float32)\n",
      "prediction_label = 5\n",
      "predicted_probability = 0.9999993\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "file = 'my-9.png'\n",
      "prediction.round(3) = array([[0.011, 0.   , 0.   , 0.001, 0.   , 0.   , 0.698, 0.   , 0.29 ]],\n",
      "      dtype=float32)\n",
      "prediction_label = 7\n",
      "predicted_probability = 0.6984565\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "file = 'sudoku-blank.png'\n",
      "prediction.round(3) = array([[0.986, 0.   , 0.003, 0.   , 0.   , 0.   , 0.009, 0.   , 0.001]],\n",
      "      dtype=float32)\n",
      "prediction_label = 1\n",
      "predicted_probability = 0.98628634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "file = 'my-4.png'\n",
      "prediction.round(3) = array([[0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)\n",
      "prediction_label = 4\n",
      "predicted_probability = 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "file = 'sudoku-8.png'\n",
      "prediction.round(3) = array([[0., 0., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32)\n",
      "prediction_label = 8\n",
      "predicted_probability = 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "file = 'sudoku-9.png'\n",
      "prediction.round(3) = array([[0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)\n",
      "prediction_label = 9\n",
      "predicted_probability = 0.9999999\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "file = 'my-5.png'\n",
      "prediction.round(3) = array([[0., 0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float32)\n",
      "prediction_label = 5\n",
      "predicted_probability = 0.99994576\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "file = 'my-7.png'\n",
      "prediction.round(3) = array([[0.   , 0.   , 0.   , 0.   , 0.017, 0.   , 0.983, 0.   , 0.   ]],\n",
      "      dtype=float32)\n",
      "prediction_label = 7\n",
      "predicted_probability = 0.98263526\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "file = 'my-6.png'\n",
      "prediction.round(3) = array([[0.   , 0.   , 0.001, 0.001, 0.   , 0.999, 0.   , 0.   , 0.   ]],\n",
      "      dtype=float32)\n",
      "prediction_label = 6\n",
      "predicted_probability = 0.9988784\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "file = 'my-2.png'\n",
      "prediction.round(3) = array([[0., 1., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)\n",
      "prediction_label = 2\n",
      "predicted_probability = 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "file = 'my-3.png'\n",
      "prediction.round(3) = array([[0., 0., 1., 0., 0., 0., 0., 0., 0.]], dtype=float32)\n",
      "prediction_label = 3\n",
      "predicted_probability = 0.99999654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "file = 'my-1.png'\n",
      "prediction.round(3) = array([[0.786, 0.024, 0.   , 0.19 , 0.   , 0.   , 0.   , 0.   , 0.   ]],\n",
      "      dtype=float32)\n",
      "prediction_label = 1\n",
      "predicted_probability = 0.7862766\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "directory = './images/toy/'\n",
    "files = os.listdir(directory)\n",
    "# resize_dim = (32,32)\n",
    "for file in files:\n",
    "    if file == '2022-us-sudoku-grand-prix-round.png':\n",
    "        pass\n",
    "    else:\n",
    "        full_path = directory + file\n",
    "        image = cv2.imread(full_path)\n",
    "        image = image_to_pixels(image)\n",
    "        image = preprocess_pixels(image)\n",
    "        prediction = model.predict(image)\n",
    "        prediction_label = prediction.argmax() + 1\n",
    "        predicted_probability = prediction.max()\n",
    "        print(f'{file = }')\n",
    "        print(f'{prediction.round(3) = }')\n",
    "        print(f'{prediction_label = }')\n",
    "        print(f'{predicted_probability = }')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model performs above 95% on the real Sudoku digits, so we will save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('./models/cnn_8.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a lot of trial and error we reached the best model so far being the cnn_5.h5 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
