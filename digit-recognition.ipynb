{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory, File Management\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Data Exploration\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Data Tracking\n",
    "import mlflow\n",
    "# Utils\n",
    "from utils import image_to_pixels, preprocess_pixels\n",
    "# Data Preprocessing, Evaluation\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "# ML Models\n",
    "from xgboost import XGBClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/14f18a74de1c40b088c464a0d3a55c83', creation_time=1713456323645, experiment_id='0', last_update_time=1713456323645, lifecycle_stage='active', name='sudoku-digit-recognition', tags={}>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()\n",
    "mlflow.set_tracking_uri(os.environ['MLFLOW_TRACKING_URI'])\n",
    "mlflow.set_experiment('sudoku-digit-recognition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two datasets:\n",
    "1. Chars74k (only Digits)\n",
    "2. TMNIST (Typeface MNIST)\n",
    "\n",
    "I have modified both datasets as following:  \n",
    "- The Chars74k dataset contains a total of 9,144 images 1,016 images for each digit from 1~9.\n",
    "- The TMNIST dataset contains a total of 26,910 images 2,990 images for each digit from 1~9.\n",
    "\n",
    "Modifications to the datasets:  \n",
    "- I have erased all the 0 digit images and pixel rows in both datasets for various reasons. We have to take into account that there is no need for our digit recognition model to recognize the digit '0' because we are creating a model specialized for Sudoku. As a reminder, Sudoku is a puzzle that involves only the digits from 1-9.  \n",
    "- Also, I dropped the 'names' column from the TMNIST dataset as the font-family doesn't provide much information for classification.\n",
    "- I have only collected datasets such that the amount of images are equal for each of the digits because on my first attempt to doing this project, I noticed that during the softmax layer to classify a digit, when the model is unsure of the digit, it will be biased to predict the number with the most frequency in the training set. For my first attempt the distribution of the dataset had been unbalanced with having more 1's than any other digit and so for digits that look similar such as 7 or 9 when the model was unsure it would predict 1.\n",
    "- finally, I inverted the pixel values from the TMNIST because I realized that the font is white and the background is black. So I subtracted the pixel values from 255.\n",
    "\n",
    "p.s. Also, I am not including handwritten digits from datasets such as MNIST in this project because those digit formats are irrelevant to a Sudoku puzzle, which is mostly printed or made with computer fonts.\n",
    "\n",
    "Some advantages of doing so:\n",
    "1. by focusing on the digits that are relevant to the task, the model will be more specialized and better suited for the intended application.\n",
    "2. it simplifies the training process and reduces the complexity of the model, leading to a faster training time and potentially better performance on the digits relevant to the task.\n",
    "3. it helps balance the distribution of digits in the dataset preventing the model from being biased towards the majority class (1-9) and improve its ability to generalize.\n",
    "4. reduce some bias and noise to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try to match all the images from the chars74k dataset to a pandas dataframe like the TMNIST_Data.csv so that we can concatenate them in the same format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory_path = './images/chars74k'\n",
    "\n",
    "# row_list = []\n",
    "# for folder in os.listdir(directory_path)[1:]:\n",
    "#     subfolder = os.path.join(directory_path, folder)\n",
    "#     for file in os.listdir(subfolder):\n",
    "#         file = os.path.join(subfolder, file)\n",
    "#         image = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "#         image = cv2.resize(image, (28,28))\n",
    "#         flatten_image = image.flatten()\n",
    "#         data = {'labels': int(folder), **{f'{i+1}': value for i, value in enumerate(flatten_image)}}\n",
    "#         row_list.append(data)\n",
    "# df_chars74k = pd.DataFrame(row_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the dataset as a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_chars74k.to_csv('./data/chars74k.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see a random image from both datasets and see that the pixel sizes and the grayscale match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tmnist = pd.read_csv('./data/tmnist.csv')\n",
    "tmnist_2d = np.reshape(df_tmnist.iloc[1,1:], (28,28)).astype(np.uint8)\n",
    "df_chars74k = pd.read_csv('./data/chars74k.csv')\n",
    "chars74k_2d = np.reshape(df_chars74k.iloc[1,1:], (28,28)).astype(np.uint8)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(tmnist_2d, cmap='gray')\n",
    "plt.title('TMNIST')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(chars74k_2d, cmap='gray')\n",
    "plt.title('Charks74k')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's vertically concatenate both datasets into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9139</th>\n",
       "      <td>5</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9140</th>\n",
       "      <td>5</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9141</th>\n",
       "      <td>5</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9142</th>\n",
       "      <td>5</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9143</th>\n",
       "      <td>5</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36054 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels    1    2    3    4    5    6    7    8    9  ...  775  776  777  \\\n",
       "0          2  255  255  255  255  255  255  255  255  255  ...  255  255  255   \n",
       "1          8  255  255  255  255  255  255  255  255  255  ...  255  255  255   \n",
       "2          4  255  255  255  255  255  255  255  255  255  ...  255  255  255   \n",
       "3          3  255  255  255  255  255  255  255  255  255  ...  255  255  255   \n",
       "4          1  255  255  255  255  255  255  255  255  255  ...  255  255  255   \n",
       "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "9139       5  255  255  255  255  255  255  255  255  255  ...  255  255  255   \n",
       "9140       5  255  255  255  255  255  255  255  255  255  ...  255  255  255   \n",
       "9141       5  255  255  255  255  255  255  255  255  255  ...  255  255  255   \n",
       "9142       5  255  255  255  255  255  255  255  255  255  ...  255  255  255   \n",
       "9143       5  255  255  255  255  255  255  255  255  255  ...  255  255  255   \n",
       "\n",
       "      778  779  780  781  782  783  784  \n",
       "0     255  255  255  255  255  255  255  \n",
       "1     255  255  255  255  255  255  255  \n",
       "2     255  255  255  255  255  255  255  \n",
       "3     255  255  255  255  255  255  255  \n",
       "4     255  255  255  255  255  255  255  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  \n",
       "9139  255  255  255  255  255  255  255  \n",
       "9140  255  255  255  255  255  255  255  \n",
       "9141  255  255  255  255  255  255  255  \n",
       "9142  255  255  255  255  255  255  255  \n",
       "9143  255  255  255  255  255  255  255  \n",
       "\n",
       "[36054 rows x 785 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_tmnist, df_chars74k], axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check once again that the distribution is uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['labels'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(df['labels'].value_counts().index, df['labels'].value_counts().values)\n",
    "# plt.title('Label Distribution')\n",
    "# plt.xlabel('Label')\n",
    "# plt.ylabel('Counts')\n",
    "# plt.xticks(df['labels'].value_counts().index)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to make augmentation of blank images and we will make the model predict them as 0. I will take screenshots of blank boxes with a little bit of the border left in the image and make enough augmented images to match the distribution of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_folder = \"./images/blank\"\n",
    "# image_paths = [os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
    "\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=0,  # Disable random rotation\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True)\n",
    "\n",
    "# num_images = len(image_paths)\n",
    "# images_per_image = 4006 // num_images\n",
    "# remainder = 4006 % num_images\n",
    "\n",
    "# output_folder = \"./images/blank_aug\"\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.makedirs(output_folder)\n",
    "\n",
    "# for image_path in image_paths:\n",
    "#     img = load_img(image_path)\n",
    "#     x = img_to_array(img)\n",
    "\n",
    "#     i = 0\n",
    "#     num_augmentations = images_per_image\n",
    "#     if remainder > 0:\n",
    "#         num_augmentations += 1\n",
    "#         remainder -= 1\n",
    "\n",
    "#     while i < num_augmentations:\n",
    "#         for angle in [90, 180, 270]:\n",
    "#             x_aug = datagen.apply_transform(x, {'theta': angle})\n",
    "#             x_aug = x_aug.reshape((1,) + x_aug.shape)  # Reshape to (1, height, width, channels)\n",
    "#             for batch in datagen.flow(x_aug, batch_size=1, save_to_dir=output_folder, save_prefix='aug', save_format='png'):\n",
    "#                 i += 1\n",
    "#                 if i >= num_augmentations:\n",
    "#                     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will repeat the same process as the Chars74k dataset and make these augmented blank images into a pandas dataframe with labels 0 and 784 columns with the pixel values in grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory_path = './images/blank_aug'\n",
    "\n",
    "# row_list = []\n",
    "# for file in os.listdir(directory_path):\n",
    "#     file = os.path.join(directory_path, file)\n",
    "#     image = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "#     image = cv2.resize(image, (28,28))\n",
    "#     flatten_image = image.flatten()\n",
    "#     data = {'labels': 0, **{f'{i+1}': value for i, value in enumerate(flatten_image)}}\n",
    "#     row_list.append(data)\n",
    "# df_blank = pd.DataFrame(row_list)\n",
    "# df_blank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking on some of the images there were some that were completely black for some unknown reason so we will track all of the images that are completely black and revert them to white blank images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_blank_0s = (df_blank.iloc[:, 1:] == 0).all(axis=1)\n",
    "\n",
    "# df_blank.loc[df_blank_0s, df_blank.columns[1:]] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_blank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's concatenate it to the main dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat([df, df_blank], axis=0)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the distribution once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(df['labels'].value_counts().index, df['labels'].value_counts().values)\n",
    "# plt.title('Label Distribution')\n",
    "# plt.xlabel('Label')\n",
    "# plt.ylabel('Counts')\n",
    "# plt.xticks(df['labels'].value_counts().index)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The augmentation worked and the 0 labels have a lower distribution than the other labels, but there isn't a lot of features in blank images so this seems okay. It seems to be really hard to for the tensorflow.keras.processing.image DataGenerator to work with the blank images.\n",
    "\n",
    "Now we save the concatenated data so that from now on we can work with the full dataset csv and can comment out all of the process above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('./data/digit_recognition.csv', index=False)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data into Train, Validation, Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39373</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39374</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39375</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39376</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39377</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39378 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels    1    2    3    4    5    6    7    8    9  ...  775  776  \\\n",
       "0           2  255  255  255  255  255  255  255  255  255  ...  255  255   \n",
       "1           8  255  255  255  255  255  255  255  255  255  ...  255  255   \n",
       "2           4  255  255  255  255  255  255  255  255  255  ...  255  255   \n",
       "3           3  255  255  255  255  255  255  255  255  255  ...  255  255   \n",
       "4           1  255  255  255  255  255  255  255  255  255  ...  255  255   \n",
       "...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "39373       0   15   15   15   15   15   15   15   15   15  ...  255  255   \n",
       "39374       0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
       "39375       0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
       "39376       0    7   34   34   34   34   34   34   34   34  ...  255  255   \n",
       "39377       0   19  255  255  255  255  255  255  255  255  ...   34   34   \n",
       "\n",
       "       777  778  779  780  781  782  783  784  \n",
       "0      255  255  255  255  255  255  255  255  \n",
       "1      255  255  255  255  255  255  255  255  \n",
       "2      255  255  255  255  255  255  255  255  \n",
       "3      255  255  255  255  255  255  255  255  \n",
       "4      255  255  255  255  255  255  255  255  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "39373  255  255  255  253  252   36   16   21  \n",
       "39374    0    0    0    0    0    0    0    0  \n",
       "39375    0    0    0    0    0    0    0    0  \n",
       "39376  253  253  253  253  253  253  253  255  \n",
       "39377   33   33   33   33   33   33   33   33  \n",
       "\n",
       "[39378 rows x 785 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/digit_recognition.csv')\n",
    "# df = df.loc[df['labels']!=0]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data will be separated into X and y then we split the train, validation, and test sets with stratified sampling on the labels.\n",
    "\n",
    "The steps will be:\n",
    "1. separate the X and y.\n",
    "2. check the shape to make sure the dimensions are right.\n",
    "3. separate into train and test sets with the stratify parameter being the label feature.\n",
    "4. separate into train and val sets with the stratify parameter being the label features again.\n",
    "5. then drop the label column from X because it was only used for stratification.\n",
    "6. check the shape to make sure the dimensions are right again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, df.iloc[:,0], test_size=0.1, stratify=df.iloc[:,0])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, stratify=X_train.iloc[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets check that the shapes are correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (31896, 785)\n",
      "y_train.shape = (31896,)\n",
      "X_val.shape = (3544, 785)\n",
      "y_val.shape = (3544,)\n",
      "X_test.shape = (3938, 785)\n",
      "y_test.shape = (3938,)\n"
     ]
    }
   ],
   "source": [
    "print(f'{X_train.shape = }')\n",
    "print(f'{y_train.shape = }')\n",
    "print(f'{X_val.shape = }')\n",
    "print(f'{y_val.shape = }')\n",
    "print(f'{X_test.shape = }')\n",
    "print(f'{y_test.shape = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can drop the label columns for all the X datasets as it was only left there for stratification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns='labels', inplace=True)\n",
    "X_val.drop(columns='labels', inplace=True)\n",
    "X_test.drop(columns='labels', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (31896, 784)\n",
      "y_train.shape = (31896,)\n",
      "X_val.shape = (3544, 784)\n",
      "y_val.shape = (3544,)\n",
      "X_test.shape = (3938, 784)\n",
      "y_test.shape = (3938,)\n"
     ]
    }
   ],
   "source": [
    "print(f'{X_train.shape = }')\n",
    "print(f'{y_train.shape = }')\n",
    "print(f'{X_val.shape = }')\n",
    "print(f'{y_val.shape = }')\n",
    "print(f'{X_test.shape = }')\n",
    "print(f'{y_test.shape = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will convert all the datasets to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "X_val = X_val.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "y_train = y_train.to_numpy()\n",
    "y_val = y_val.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = mm_scaler.fit_transform(X_train)\n",
    "X_val_scaled = mm_scaler.transform(X_val)\n",
    "X_test_scaled = mm_scaler.transform(X_test)\n",
    "# y_train, y_val, y_test = y_train -1, y_val-1, y_test-1\n",
    "# X_train_255, X_val_255, X_test_255 = X_train / 255, X_val / 255, X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_255, X_val_255, X_test_255 = X_train / 255, X_val / 255, X_test / 255\n",
    "# from numpy.testing import assert_almost_equal\n",
    "# assert_almost_equal(X_train_255, X_train_scaled)\n",
    "# assert_almost_equal(X_val_255, X_val_scaled)\n",
    "# assert_almost_equal(X_test_255, X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we will perform machine learning. We will use different models and compare their evaluations to decide which one to use.  \n",
    "\n",
    "The three models that I will try are:\n",
    "1. XGBoost (Ensemble Random Forest), \n",
    "2. Neural Network, \n",
    "3. Convolutional Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9830699774266366\n",
      "Testing Accuracy: 0.9834941594718131\n",
      "Confusion Matrix:\n",
      "[[332   0   0   0   0   0   0   0   0   0]\n",
      " [  0 393   2   0   1   0   0   4   0   1]\n",
      " [  0   4 393   1   0   0   1   0   0   1]\n",
      " [  0   3   1 392   0   2   1   2   0   0]\n",
      " [  0   3   0   0 396   0   0   0   0   2]\n",
      " [  0   0   0   0   0 397   2   0   1   0]\n",
      " [  0   0   0   0   3   4 391   0   3   0]\n",
      " [  0   3   0   1   0   1   0 394   1   1]\n",
      " [  0   2   2   0   0   1   1   1 393   1]\n",
      " [  0   0   0   1   3   0   0   2   2 392]]\n",
      "F1 Score: 0.9835028620113444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertopark/Documents/code-projects/datascience-projects/sudoku-solver-app/.venv/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [20:53:03] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"XGBClassifier\"):\n",
    "    params = {\n",
    "        'objective': 'multi:softmax',\n",
    "        'num_class': 10,\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.3,\n",
    "        'n_estimators': 100\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    xgb = XGBClassifier(\n",
    "        objective='multi:softmax',\n",
    "        num_class=10,  \n",
    "        max_depth=6,  \n",
    "        learning_rate=0.3,  \n",
    "        n_estimators=100\n",
    "    )\n",
    "    xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_val_pred = xgb.predict(X_val_scaled)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "    y_test_pred = xgb.predict(X_test_scaled)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    \n",
    "    f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "    print(\"F1 Score:\", f1)\n",
    "    \n",
    "    metrics = {\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        # 'confusion_matrix': conf_matrix,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "    \n",
    "    xgb.save_model('./models/xgb.json')\n",
    "    \n",
    "    mlflow.log_metrics(metrics)\n",
    "    \n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d')\n",
    "    # plt.xlabel('Predicted labels')\n",
    "    # plt.ylabel('True labels')\n",
    "    # plt.title('Confusion Matrix')\n",
    "    # plt.savefig('confusion_matrix.png')\n",
    "    # plt.close()\n",
    "    # mlflow.log_artifact('confusion_matrix.png')\n",
    "    \n",
    "    mlflow.xgboost.log_model(xgb, \"xgboost-model\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image = 'sudoku-1.png'\n",
      "Prediction Label: 1\n",
      "Prediction Score: [[-5.629  7.266 -6.219 -3.007 -1.332 -2.413 -7.072 -3.235 -5.939 -4.674]]\n",
      "image = 'sudoku-2.png'\n",
      "Prediction Label: 2\n",
      "Prediction Score: [[-5.629 -5.412  9.947 -3.251 -6.991 -6.121 -5.259 -3.297 -4.292 -4.157]]\n",
      "image = 'sudoku-3.png'\n",
      "Prediction Label: 3\n",
      "Prediction Score: [[-5.629 -5.323 -4.299  5.993 -6.001 -4.046 -6.105 -4.275 -2.556 -4.523]]\n",
      "image = 'sudoku-7.png'\n",
      "Prediction Label: 7\n",
      "Prediction Score: [[-5.594 -4.681 -1.634 -3.75  -4.95  -5.641 -6.953  6.095 -2.538 -4.673]]\n",
      "image = 'sudoku-6.png'\n",
      "Prediction Label: 6\n",
      "Prediction Score: [[-5.629 -6.417 -5.477 -6.001 -5.004 -3.145  3.914 -6.502  2.938 -5.955]]\n",
      "image = 'sudoku-4.png'\n",
      "Prediction Label: 4\n",
      "Prediction Score: [[-5.588 -3.868 -4.686 -5.062 10.236 -4.619 -3.696 -6.317 -2.467 -4.939]]\n",
      "image = 'sudoku-5.png'\n",
      "Prediction Label: 5\n",
      "Prediction Score: [[-5.629 -5.546 -5.826 -5.75  -5.341  8.298 -0.88  -6.487 -4.028 -5.618]]\n",
      "image = 'sudoku-blank.png'\n",
      "Prediction Label: 7\n",
      "Prediction Score: [[-4.763 -3.21  -6.013 -5.522 -3.639 -5.131 -4.745 -3.156 -5.998 -4.935]]\n",
      "image = 'sudoku-8.png'\n",
      "Prediction Label: 8\n",
      "Prediction Score: [[-5.629 -6.59  -2.845 -4.826 -4.643 -5.33  -1.401 -6.044  5.543 -5.44 ]]\n",
      "image = 'sudoku-9.png'\n",
      "Prediction Label: 9\n",
      "Prediction Score: [[-4.921 -6.554 -2.773 -4.886 -4.161 -2.409 -2.699 -5.626 -2.862  5.33 ]]\n"
     ]
    }
   ],
   "source": [
    "rel_path = './images/toy/'\n",
    "for image in os.listdir(rel_path):\n",
    "    if image.startswith('sudoku') and image.endswith('.png'):\n",
    "        print(f'{image = }')\n",
    "        image = cv2.imread(rel_path+image)\n",
    "\n",
    "        image = image_to_pixels(image, (28,28)).flatten()\n",
    "        image = mm_scaler.transform([image])\n",
    "        image = image.reshape(1, -1)\n",
    "        predictions = xgb.predict(image, output_margin=True)\n",
    "\n",
    "        print(f'Prediction Label: {predictions.argmax()}')\n",
    "        print(f'Prediction Score: {predictions.round(3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a CNN you need to preprocess the pixels before you feed them into the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess images for Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the X holds the value of file path to the image and so we need to be able to get the images in those file paths, convert those images into pixel values and then make each pixel value be one feature or column in the new X.\n",
    "\n",
    "Until now we were exploring and cleaning data from different datasets with different structures but now that we have combined and we are ready for preprocessing the data for machine learning, we will be using functions later to be saved in the utils.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "def df_to_pixels_array(df:pd.DataFrame, label:str, resize_dim:tuple, rel_path) -> np.array:\n",
    "    \"\"\"\n",
    "    Takes a column from a pandas dataframe that has the values for the file path of images.\n",
    "    Then it reads the files, converts them to grayscale and flattens the pixel values\n",
    "    to finally return a numpy array of those values.\n",
    "\n",
    "    Parameters:\n",
    "    df_filepath (dataframe): The dataframe to process.\n",
    "    label (string): The name of the column containing the file paths\n",
    "    resize (tuple): The dimensions to resize the image before flattening.\n",
    "    rel_path (string): The relative file path before the value in the dataframe column.\n",
    "\n",
    "    Returns:\n",
    "    array: (m, n) numpy array of grayscale pixel values.\n",
    "            m -> # of images\n",
    "            n -> product of resize tuple provided\n",
    "    \"\"\"\n",
    "    i = len(df[label])\n",
    "    m = resize_dim[0]\n",
    "    n = resize_dim[1]\n",
    "    df_array = np.zeros((i, m, n), dtype=np.uint8)\n",
    "    for index, file_path in enumerate(df[label]):\n",
    "        file_path = rel_path + file_path\n",
    "        image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.equalizeHist(image)\n",
    "        image = cv2.resize(image, resize_dim)\n",
    "        if image is None:\n",
    "            print(\"Error: Unable to read the image.\")\n",
    "            print(file_path)\n",
    "        else:\n",
    "            df_array[index] = image\n",
    "    return df_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_path = './images/numbers/'\n",
    "label = 'file'\n",
    "resize_dim = (32,32)\n",
    "X_train = df_to_pixels_array(X_train, label, resize_dim, rel_path)\n",
    "X_val = df_to_pixels_array(X_val, label, resize_dim, rel_path)\n",
    "X_test = df_to_pixels_array(X_test, label, resize_dim, rel_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the dimensions and datatypes are correct for X_train, X_val, and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{X_train.shape = }')\n",
    "print(f'{X_val.shape = }')\n",
    "print(f'{X_test.shape = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time for further preprocessing before we train the Convolutional Neural Network for it to be able to predict numbers.  \n",
    "Specifically, we are going to normalize the data. Right now, the range of each pixel is from 0, 255 with 0 being black and 255 white. By normalizing the data the range will be from 0~1 conserving the ratio, and this will help the model to converge more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.keras.utils.normalize(X_train, axis=1)\n",
    "X_train = np.array(X_train).reshape(-1, resize_dim[0], resize_dim[1], 1)\n",
    "X_val = tf.keras.utils.normalize(X_val, axis=1)\n",
    "X_val = np.array(X_val).reshape(-1, resize_dim[0], resize_dim[1], 1)\n",
    "X_test = tf.keras.utils.normalize(X_test, axis=1)\n",
    "X_test = np.array(X_test).reshape(-1, resize_dim[0], resize_dim[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Convolutional Neural Network Model to train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we build the arquitecture for the CNN and compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Conv2D(32, (3,3), padding='valid', activation='relu', input_shape=(X_train.shape[1:])),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32, (3,3), padding='valid', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Conv2D(64, (3,3), padding='valid', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2)),\n",
    "        Conv2D(64, (3,3), padding='valid', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(512,activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.25),\n",
    "        Dense(1024,activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.25),\n",
    "        Dense(9, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(\n",
    "    optimizer=optimizer, \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we fit the model we are going to generate batches of augmented data for the X_train and y_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min')\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=10,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     # horizontal_flip=True,\n",
    "#     fill_mode='nearest'\n",
    "# )\n",
    "# datagen.fit(X_train)\n",
    "# train_generator = datagen.flow(X_train, y_train-1, batch_size=32)\n",
    "# model.fit(train_generator, validation_data= (X_val, y_val-1), epochs=5)\n",
    "model.fit(X_train, y_train, validation_data= (X_val, y_val), epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model to the train data, and subtract 1 from y_train as the outputlayer contains 1~9 but counting starts from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train, y_train - 1, epochs=3, validation_split=0.2, batch_size=32, verbose='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model to see how it did on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'{loss = }')\n",
    "print(f'{accuracy = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make some functions to preprocess the images for the models to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_pixels(image:np.array) -> np.array:\n",
    "    resize_dim = (32, 32)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    equalized_image = cv2.equalizeHist(gray_image)\n",
    "    image = cv2.resize(equalized_image, resize_dim)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pixels(image:np.array) -> np.array:\n",
    "    resize_dim = (32,32)\n",
    "    normalized_image = tf.keras.utils.normalize(image, axis=1)\n",
    "    preprocessed_image = np.array(normalized_image).reshape(-1, resize_dim[0], resize_dim[1], 1)\n",
    "    return preprocessed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to see how well the model predicts with toy data from self made handwritten digits, which is not that very important compared to the actual digits that real Sudoku would hold (mostly computer font digits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = './images/toy/'\n",
    "files = os.listdir(directory)\n",
    "# resize_dim = (32,32)\n",
    "for file in files:\n",
    "    if file == '2022-us-sudoku-grand-prix-round.png':\n",
    "        pass\n",
    "    else:\n",
    "        full_path = directory + file\n",
    "        image = cv2.imread(full_path)\n",
    "        image = image_to_pixels(image)\n",
    "        image = preprocess_pixels(image)\n",
    "        prediction = model.predict(image)\n",
    "        prediction_label = prediction.argmax() + 1\n",
    "        predicted_probability = prediction.max()\n",
    "        print(f'{file = }')\n",
    "        print(f'{prediction.round(3) = }')\n",
    "        print(f'{prediction_label = }')\n",
    "        print(f'{predicted_probability = }')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model performs above 95% on the real Sudoku digits, so we will save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/cnn_8.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a lot of trial and error we reached the best model so far being the cnn_5.h5 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
